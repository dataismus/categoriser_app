{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "#client_bq = bigquery.Client.from_service_account_json(\"./credentials.json\", project='charged-dialect-824')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_load = load_bq_data(sql)\\nlen(df_load)\\ndf_load.head()'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_bq_data(_sql):\n",
    "    _df = client_bq.query(_sql).to_dataframe()\n",
    "    return _df\n",
    "\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT *\n",
    "FROM RicardoInterview.product_detection_training_data\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"df_load = load_bq_data(sql)\n",
    "len(df_load)\n",
    "df_load.head()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_load.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief look at the sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=pd.read_csv(\"ricardo_data.csv\", sep='|', index_col=0)\n",
    "#raw=df_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleId</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>productType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-24471100344624315</td>\n",
       "      <td>Metal Hurlant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>magazine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4941423510709663049</td>\n",
       "      <td>Mikrophone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sound_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6882901079846443092</td>\n",
       "      <td>Sound Blaster Audigy CREATIVE</td>\n",
       "      <td>Soundkarte für PC</td>\n",
       "      <td>sound_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-309151326745158426</td>\n",
       "      <td>Umlenkrolle Forst, extra leicht</td>\n",
       "      <td>100 kn / 10 Tonnen</td>\n",
       "      <td>winch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3342786788349504714</td>\n",
       "      <td>MATSCHFACH MORITZ SPEZIAL</td>\n",
       "      <td>*GRATIS LIEFERUNG*</td>\n",
       "      <td>sandpit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             articleId                            title            subtitle  \\\n",
       "0   -24471100344624315                    Metal Hurlant                 NaN   \n",
       "1 -4941423510709663049                       Mikrophone                 NaN   \n",
       "2  6882901079846443092    Sound Blaster Audigy CREATIVE   Soundkarte für PC   \n",
       "3  -309151326745158426  Umlenkrolle Forst, extra leicht  100 kn / 10 Tonnen   \n",
       "4 -3342786788349504714        MATSCHFACH MORITZ SPEZIAL  *GRATIS LIEFERUNG*   \n",
       "\n",
       "  productType  \n",
       "0    magazine  \n",
       "1  sound_card  \n",
       "2  sound_card  \n",
       "3       winch  \n",
       "4     sandpit  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Are there even any duplicates in the current state of the frame?\n",
      "\n",
      "True\n",
      "\n",
      "How about now?\n",
      "\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAre there even any duplicates in the current state of the frame?\\n\")\n",
    "print(raw.duplicated(keep=False).any())\n",
    "if raw.duplicated(keep=False).any():\n",
    "    raw.drop_duplicates(inplace=True)\n",
    "    print(\"\\nHow about now?\\n\")\n",
    "    print(raw.duplicated(keep=False).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37073 labeled samples for 383 (!) target classes\n"
     ]
    }
   ],
   "source": [
    "y=np.array(raw.productType)\n",
    "classes=np.unique(y)\n",
    "print(\"{} labeled samples for {} (!) target classes\".format(len(y), len(classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A histogram of the frequencies of each product type in the sample set allows us to quickly confirm:\n",
    "1. whether there are imbalances in the representation of target classes: Rather not, as all classes are represented by 50-99 samples, i.e. not even a single order of magnitude apart - this is quite a balanced set for a multiclass classifier.\n",
    "2. whether there are serious outliers or even misspells etc in the taxonomy: no, the Product type column is clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(raw.productType.value_counts().hist()) # all classes represented n times, where 48<n<99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(marble        46\n",
       " dump_truck    52\n",
       " holster       59\n",
       " Name: productType, dtype: int64,\n",
       " mirror_cabinet    99\n",
       " lamp              99\n",
       " car               99\n",
       " Name: productType, dtype: int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Indeed:\n",
    "raw.productType.value_counts().sort_values()[:3], raw.productType.value_counts().sort_values()[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some early thoughts on the goal of this exercise:**\n",
    "1. As the dataset is so balanced, even plain accuracy of the resulting model is a reliable metric for choosing a good variant.\n",
    "2. Given the nature of the product *categorization task*, we do not really have a preference for minimizing Type I or Type II errors (in other words, we don't prioritize precision or recall when evaluating the classifier). A well-calibrated model with the highest possible generaization accuracy is the goal.\n",
    "\n",
    "I will be evaluating alternatives using the **mean F1 score** (a harmonic mean of precision and recall), as the general best practice for scoring performance of multi-class classifiers, but the terms \"f1 score\" and \"accuracy\" can be used interchangeably, as the actual values will not differ much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial transformation to a BoF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining **title & subtitle as a single feature string** (after addressing empty subtitles): the rough(!) assumption is that the subtitles are not strictly inferior in informativeness for the target class to the main titles, as Ricardo users are not prompted so when entering. This hypothesis is worth examining, but not now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = raw.replace(np.nan,'', regex=True)\n",
    "raw[\"descr\"]=raw.title+\" \"+raw.subtitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The entire training corpus combined consists of 1647713 total characters in 252497 total words\n"
     ]
    }
   ],
   "source": [
    "all_of_it = raw.descr.str.cat(sep=' ')\n",
    "print(\"The entire training corpus combined consists of\", len(all_of_it), 'total characters in', len(all_of_it.split(\" \")), 'total words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Bag-of-words vectorization of the assembled title strings and subsequent further transformation of the vocabulary:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import spacy  # for lemmatization\n",
    "import nltk   # for word stemming\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import bof_utils\n",
    "lexicon = spacy.load(\"de_core_news_sm\")\n",
    "# lexicon = spacy.load(\"de\")\n",
    "bof_utils.nlp=lexicon\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk_stopwords_de = nltk.corpus.stopwords.words('german')\n",
    "spacy_stopwords_de = spacy.lang.de.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jawohl', ',', 'dies', 'Auto', 'hören', 'sich', ',', 'warum', 'nicht', ',', 'meinen', 'Mann', ',', 'haben', 'ich', 'auch', 'einen', 'gleich', '?']\n"
     ]
    }
   ],
   "source": [
    "print(bof_utils.lemmatizer(\"jawohl, dieses Auto gehört mir, warum nicht, mein Mann, haben Sie auch ein gleiches?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jawohl', 'dies', 'Auto', 'gehören', 'mir', 'warum', 'nicht', 'mein', 'Mann', 'haben', 'Sie', 'auch', 'ein', 'gleiches']\n"
     ]
    }
   ],
   "source": [
    "print(bof_utils.de_blob_lemmatizer(\"jawohl, dieses Auto gehört mir, warum nicht, mein Mann, haben Sie auch ein gleiches\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 43977, training set size: 37073 samples * 43977 features\n",
      "# of tokens automatically excluded from the vocabulary: 0\n"
     ]
    }
   ],
   "source": [
    "_, bag= bof_utils.BoF(data=raw.descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = bag.get_feature_names()\n",
    "corpus_vocab_count_dict={w:c for (w,c) in zip(vocab, bag.transform([all_of_it]).toarray()[0])}\n",
    "sorted_corpus_count=sorted(corpus_vocab_count_dict.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('in', 959),\n",
       " ('gr', 1007),\n",
       " ('von', 1029),\n",
       " ('cm', 1196),\n",
       " ('und', 1391),\n",
       " ('neu', 1399),\n",
       " ('für', 2054),\n",
       " ('mit', 3604)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_corpus_count[-8:] # potentially uninformative, too frequent tokens (mostly German stopwords) at the top of the vocabulary pile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0018m2', 1),\n",
       " ('002', 1),\n",
       " ('003160', 1),\n",
       " ('0041', 1),\n",
       " ('0057', 1),\n",
       " ('00687', 1),\n",
       " ('006r01264', 1),\n",
       " ('008r13021', 1)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_corpus_count[:8] # potentially uninformative, too infrequent tokens at the bottom of the vocabulary pile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants=defaultdict(lambda: defaultdict(dict))\n",
    "variants[\"default_vectorizer\"][\"vectorizers\"]=bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Slightly more sophisticated corpus representation - dropping German stopwords:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ToDo**: Would be intriguing to build a language recognition pipeline based on this:\n",
    "https://data-science-blog.com/blog/2018/11/12/language-detecting-with-sklearn-by-determining-letter-frequencies/\n",
    "to treat titles written in French, English, German & Italian accordingly regarding stopwords/lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 43683, training set size: 37073 samples * 43683 features\n",
      "# of tokens automatically excluded from the vocabulary: 0\n",
      "# of stopwords that were effectively excluded : 543\n"
     ]
    }
   ],
   "source": [
    "stopwords=spacy_stopwords_de\n",
    "\n",
    "_,variants[\"stopwords\"][\"vectorizers\"]= bof_utils.BoF(data=raw.descr, stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rescaling the data with tf-idf:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 43683, training set size: 37073 samples * 43683 features\n",
      "# of tokens automatically excluded from the vocabulary: 0\n",
      "# of stopwords that were effectively excluded : 543\n"
     ]
    }
   ],
   "source": [
    "_, variants[\"w_tfidf\"][\"vectorizers\"]= bof_utils.BoF(data=raw.descr, tfidf= True, stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**and force-excluding too frequent/infrequent terms from the vocabulary:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 16249, training set size: 37073 samples * 16249 features\n",
      "# of tokens automatically excluded from the vocabulary: 27434\n",
      "# of stopwords that were effectively excluded : 543\n"
     ]
    }
   ],
   "source": [
    "_, variants[\"w_tfidf_min2_max100\"][\"vectorizers\"]= bof_utils.BoF(data=raw.descr, tfidf= True,  min_df=2, max_df=100, stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**...and enriching the feature set with some n-grams:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 38450, training set size: 37073 samples * 38450 features\n",
      "# of tokens automatically excluded from the vocabulary: 229193\n",
      "# of stopwords that were effectively excluded : 543\n"
     ]
    }
   ],
   "source": [
    "variant=\"w_tfidf_ngram_3\"\n",
    "\n",
    "_, variants[\"w_tfidf_ngram_3\"][\"vectorizers\"]= bof_utils.BoF(data=raw.descr, tfidf= True, min_df=2, ngram_range=(1,3), stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Last, trying lemmatization on the vocabulary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['einigen', 'gleich', 'heiß', 'lieben', 'vergehen', 'wahr'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 16237, training set size: 37073 samples * 16237 features\n",
      "# of tokens automatically excluded from the vocabulary: 31703\n",
      "# of stopwords that were effectively excluded : 332\n"
     ]
    }
   ],
   "source": [
    "for custom_tokenizer in [bof_utils.lemmatizer]:\n",
    "    variant=custom_tokenizer.__name__+\"_w_tfidf\"\n",
    "    _,variants[variant][\"vectorizers\"]= bof_utils.BoF(data=raw.descr,custom_tokenizer=custom_tokenizer, \n",
    "                          tfidf= True, min_df=2, stop_words=custom_tokenizer(\", \".join(stopwords)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying some (basic) Classifiers on these BoF representations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " \n",
    "**Observe the sparse nature of the bag-of-words data representation, which pretty much dictates the families of models applicable:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<37073x16249 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 123910 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "X=variants[\"w_tfidf_min2_max100\"][\"vectorizers\"].transform(raw.descr)\n",
    "print(repr(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Accuracy of random guessing:*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.26 % \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n{:.2f} % \".format(100/len(classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " \n",
    "... I 'd better beat this... :P\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With data from default_vectorizer\n",
      "(vocabulary size: 43977):\n",
      "                                          train vs. test\n",
      "f1_macro of default        MultinomialNB:  0.98     0.66\n",
      "                                          train vs. test\n",
      "f1_macro of default        SGDClassifier:  0.99     0.69\n",
      "\n",
      "With data from stopwords\n",
      "(vocabulary size: 43683):\n",
      "                                          train vs. test\n",
      "f1_macro of default        MultinomialNB:  0.98     0.67\n",
      "                                          train vs. test\n",
      "f1_macro of default        SGDClassifier:  0.99     0.70\n",
      "\n",
      "With data from w_tfidf\n",
      "(vocabulary size: 43683):\n",
      "                                          train vs. test\n",
      "f1_macro of default        MultinomialNB:  0.99     0.71\n",
      "                                          train vs. test\n",
      "f1_macro of default        SGDClassifier:  0.99     0.74\n",
      "\n",
      "With data from w_tfidf_min2_max100\n",
      "(vocabulary size: 16249):\n",
      "                                          train vs. test\n",
      "f1_macro of default        MultinomialNB:  0.94     0.71\n",
      "                                          train vs. test\n",
      "f1_macro of default        SGDClassifier:  0.95     0.73\n",
      "\n",
      "With data from w_tfidf_ngram_3\n",
      "(vocabulary size: 38450):\n",
      "                                          train vs. test\n",
      "f1_macro of default        MultinomialNB:  0.95     0.70\n",
      "                                          train vs. test\n",
      "f1_macro of default        SGDClassifier:  0.97     0.74\n",
      "\n",
      "With data from lemmatizer_w_tfidf\n",
      "(vocabulary size: 16237):\n",
      "                                          train vs. test\n",
      "f1_macro of default        MultinomialNB:  0.91     0.64\n",
      "                                          train vs. test\n",
      "f1_macro of default        SGDClassifier:  0.95     0.67\n"
     ]
    }
   ],
   "source": [
    "import nested_x_val\n",
    "score_metric=\"f1_macro\"\n",
    "\n",
    "models=[MultinomialNB(alpha=.1) , SGDClassifier(random_state=101, loss=\"modified_huber\")] # LogisticRegression(C=1., warm_start=True, class_weight='balanced'),\n",
    "for variant in variants.keys():\n",
    "    print(\"\\nWith data from {}\\n(vocabulary size: {}):\".format(variant,len(variants[variant][\"vectorizers\"].get_feature_names())))\n",
    "    _=nested_x_val.model_mvp(models,\n",
    "                            variants[variant][\"vectorizers\"].transform(raw.descr),y, \n",
    "                            n_splits=3, n_jobs=1, score_metric=score_metric, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"variance_acc_plot.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some further conclusions from the prototyping:**\n",
    "1. ... appears overfitting, at this point - mode training data will smoothen the BoF-tf-idf vector and increase accuracy\n",
    "2. the **w_tfidf_min2_max100** settings for the BoF vectorization seem the best early choice: competitive accuracy but a severely downsized vocabulary size (-60% of the rest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning of estimators on chosen representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i.  Choosing between the SVC and the NB**\n",
    " \n",
    "**ii. Simultaneously applying a basic (cross-validated) grid search for optimal settings on their main regularization hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_alpha_range=[0.01,0.1,0.5,1.]\n",
    "SVM_alpha_range=[0.00001,0.0001,0.001,0.01]\n",
    "max_df_range=[50,100]\n",
    "min_df_range=[2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For the sake of validation of our choice of Bag-of-words specifics, we will actually run the hyper-tuning grid search on the entire pipeline of {data transformation --> classification}:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average f1_macro on the test set: 0.714\n",
      "Average f1_macro score on the train set: 0.949\n"
     ]
    }
   ],
   "source": [
    "e2e_pipe= Pipeline([('vectorizer',CountVectorizer()),('classifier', MultinomialNB())])\n",
    "pipe_grid= [{\"classifier\":[MultinomialNB()], \"vectorizer\": [CountVectorizer(), TfidfVectorizer()],\n",
    "            \"classifier__alpha\": NB_alpha_range, \"vectorizer__max_df\":max_df_range,\"vectorizer__min_df\":min_df_range, \"vectorizer__stop_words\":[None, stopwords]},\n",
    "            {\"classifier\":[SGDClassifier(random_state=101, loss=\"modified_huber\")], \"vectorizer\": [CountVectorizer(), TfidfVectorizer()],\n",
    "            \"classifier__alpha\": SVM_alpha_range,\"vectorizer__max_df\":max_df_range,\"vectorizer__min_df\":min_df_range, \"vectorizer__stop_words\":[None, stopwords]}]\n",
    "\n",
    "best_e2e = nested_x_val.nested_x_val_grid_search(e2e_pipe, raw.descr, y, pipe_grid, show_me_params= False, score_metric=score_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For a more comprehensive review of the final predictor (end-to-end pipeline), we can review a classification report:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model average  precision :    0.75\n",
      "Trained model average     recall :    0.71\n",
      "Trained model average   f1-score :    0.72\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw.descr,y,stratify=y, test_size=0.2,random_state=102)\n",
    "y_pred=best_e2e.fit(X_train,y_train).predict(X_test)\n",
    "report=classification_report(y_test, y_pred, output_dict=True, target_names=best_e2e.classes_)\n",
    "for metric in ['precision', 'recall', 'f1-score']: print(\"Trained model average {:>10} : {:>7.2f}\".format(metric,report['macro avg'][metric]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected for a very balanced training set, the model appears well calibrated, as precision & recall are aligned with the f1-score, and we can be confident of equivalent confidence when generalizing to new data.\n",
    "**The model is ready to be deployed**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-fitting the best model on the entire available labelled set:\n",
    "final=best_e2e.fit(raw.descr,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our prototype vectorizer:\n",
      "\n",
      " TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=100, max_features=None,\n",
      "                min_df=2, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "print(\"Our prototype vectorizer:\\n\\n\",final[\"vectorizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our prototype classifier:\n",
      "\n",
      " SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='modified_huber',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=101, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(\"Our prototype classifier:\\n\\n\",final[\"classifier\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ready for top-5 Product types predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "an_example_title=\"Blaster Moritz Mikrophone Batman Batman und Woot 10 100 Dimitrios Batman\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BoF representation of the to-be-classified example:\n",
      "{'moritz': 0.27391349074706517, 'mikrophone': 0.2940234097739994, 'blaster': 0.2459141001151946, 'batman': 0.8820702293219981}\n"
     ]
    }
   ],
   "source": [
    "X_example=final[\"vectorizer\"].transform([an_example_title])\n",
    "vocab_in_example=list(X_example.nonzero()[1])   # remember, the sample is of sparse matrix type, NOT a dense array or list!\n",
    "vocab=final[\"vectorizer\"].get_feature_names()\n",
    "print(\"The BoF representation of the to-be-classified example:\")\n",
    "print({vocab[i]:X_example[0, i] for i in vocab_in_example})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this all needs to be packaged as a single output function for the flask service:\n",
    "import json\n",
    "def predict_top5(doc, classifier):\n",
    "        \n",
    "    probas=classifier.predict_proba(doc)[0]\n",
    "    top5=np.argsort(probas)[-5:]\n",
    "        \n",
    "    #requested JSON elements:\n",
    "    title=doc\n",
    "    top_5_results=[{\"product_type\": x, \"score\": \"{:.4f}\".format(y)} for (x,y) in zip(reversed(classes[top5]),reversed(probas[top5]))]\n",
    "    product_type=classes[top5][-1]\n",
    "    return json.dumps({\"title\": title, \"top_5_results\": top_5_results, \"product_type\": product_type}, indent=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"title\": [\n",
      "      \"Blaster Moritz Mikrophone Batman Batman Woot 10 100 Dimitrios Batman\"\n",
      "   ],\n",
      "   \"top_5_results\": [\n",
      "      {\n",
      "         \"product_type\": \"bathrobe\",\n",
      "         \"score\": \"0.3601\"\n",
      "      },\n",
      "      {\n",
      "         \"product_type\": \"sound_card\",\n",
      "         \"score\": \"0.2752\"\n",
      "      },\n",
      "      {\n",
      "         \"product_type\": \"comic_book\",\n",
      "         \"score\": \"0.0765\"\n",
      "      },\n",
      "      {\n",
      "         \"product_type\": \"video_game_console\",\n",
      "         \"score\": \"0.0697\"\n",
      "      },\n",
      "      {\n",
      "         \"product_type\": \"sandpit\",\n",
      "         \"score\": \"0.0594\"\n",
      "      }\n",
      "   ],\n",
      "   \"product_type\": \"bathrobe\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(predict_top5([\"Blaster Moritz Mikrophone Batman Batman Woot 10 100 Dimitrios Batman\"], final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('trained.pkl', 'wb') as f: pickle.dump(final, f)  \n",
    "    # the BoF transformer is shipped over to the Flask service also as a component of the pipelined predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ideas for further exploration and improvement:**\n",
    " \n",
    "1. **The product taxonomy of Ricardo** is assumed robust - perhaps even some lemmaization on the target label column could identify possible merges. And then of course this ML exercise could, in the long run, even propose changes to the taxonomy, e.g. a discussion with Business Analytics\n",
    " \n",
    "2. Text data is assumed to be in German throughout (not generally true on Ricardo.ch), a careful segmentation of samples via some **language identifier** would increase the performance of the lemmatizer and remove confusion to language-agnostic BoF algorithm where the same word means a different thing in 2 languages\n",
    "\n",
    "3. **A hybrid system for prediction**: the ML model could be combined with, for example, a regex-based heuristic to improve accuracy - it doesn't all need to be AI!\n",
    "\n",
    "4. Obviously, the performance of all model alternatives (especially linear varieties) will benefit tremendously and immediately from **a larger training dataset**\n",
    "\n",
    "**-------- all of the above would help reduce the likely overfitting, which is unavoidable in early sparse text data classifiers ---------**\n",
    "\n",
    "5. **Performance vs. portability tradeoff** of the REST API app: shipping the entire Bag-of-words vocabulary with the model as one pickle object increases Docker image size, but leaving it as an external file to be read in via drive-mapping lowers prediction speed. These are important considerations for live deployment\n",
    "\n",
    "6. Moving the training/validation pipeline from Pandas/SKLearn to **Spark MLlib** on the Google Cloud would open up resource availability but also the option of batch processing, which means we can benefit from wider hyperparameter tuning Grids for our chosen models and explore all-new model options that just won't run locally\n",
    "\n",
    "**Advanced** \n",
    "\n",
    "7. **Current research** seems to suggest that, a hierarchical classification scheme (where the taxonomy is not considered flat, like we have done here, but tree like, e.g. bicycle: {bicycle, saddle, helmet}...), coupled with Convolutional/Bi-directional NN's probably represents the state-of-the-art for classification based on title: \n",
    "https://arxiv.org/pdf/1903.04254v1.pdf\n",
    "https://arxiv.org/pdf/1907.00420.pdf\n",
    "https://arxiv.org/pdf/1812.05774v1.pdf\n",
    "https://www.aclweb.org/anthology/E17-2105.pdf\n",
    "\n",
    "8. Of course, a completely different direction would be **a multi-modal system** which makes use of all the information inserted by the user, not just title (incl. images) for next-level accuracy\n",
    "\n",
    "9. So, how did you do it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
